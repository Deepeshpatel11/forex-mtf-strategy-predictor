{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# 01 - Data Collection (OANDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "**Objective:**  \n",
        "Fetch historical forex data for multiple timeframes (Weekly, Daily, 4H, 1H)  \n",
        "using the OANDA API for the following currency pairs:\n",
        "\n",
        "- EUR/USD  \n",
        "- USD/JPY  \n",
        "- GBP/USD  \n",
        "- USD/CHF  \n",
        "- AUD/USD  \n",
        "- USD/CAD  \n",
        "- NZD/USD\n",
        "\n",
        "**Tasks:**  \n",
        "1. Connect to OANDA API  \n",
        "2. Fetch historical OHLCV data for multiple timeframes  \n",
        "3. Save raw data as CSV in `data/raw/`  \n",
        "4. Verify data for use in feature engineering and ML\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/forex-mtf-strategy-predictor/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/forex-mtf-strategy-predictor'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Import Libraries and Initialize OANDA API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Objective:**  \n",
        "In this step, we import all the Python libraries required for data collection and  \n",
        "initialize the connection to the **OANDA API** using a secure `.env` file.\n",
        "\n",
        "**Key Points:**\n",
        "- We use `oandapyV20` to communicate with OANDA's REST API.\n",
        "- API credentials (`OANDA_API_KEY`) are stored securely in a `.env` file.\n",
        "- `python-dotenv` is used to load environment variables safely.\n",
        "- Successful initialization will confirm we are ready to fetch historical forex data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OANDA_API_KEY loaded: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Retrieve OANDA API key\n",
        "OANDA_API_KEY = os.getenv(\"OANDA_API_KEY\")\n",
        "\n",
        "# Verify that the key is loaded\n",
        "print(\"OANDA_API_KEY loaded:\", bool(OANDA_API_KEY))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Define Currency Pairs, Timeframes, and Output Paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Objective:**  \n",
        "In this step, we define the currency pairs that we will collect **1-hour OHLC data** for.  \n",
        "Later, we will **resample this 1H data** to create 4H, Daily, and Weekly candles  \n",
        "instead of fetching multiple timeframes from OANDA.\n",
        "\n",
        "**Key Points:**\n",
        "- Reduces API calls and storage space.\n",
        "- Ensures all higher timeframe candles are generated consistently from 1H data.\n",
        "- Raw CSV files will be saved in `data/raw/` for feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting 43800 candles per pair (H1)\n",
            "Pairs: ['EUR_USD', 'USD_JPY', 'GBP_USD', 'USD_CHF', 'AUD_USD', 'USD_CAD', 'NZD_USD']\n"
          ]
        }
      ],
      "source": [
        "# Currency pairs to collect from OANDA\n",
        "PAIRS = [\n",
        "    \"EUR_USD\", \n",
        "    \"USD_JPY\", \n",
        "    \"GBP_USD\", \n",
        "    \"USD_CHF\", \n",
        "    \"AUD_USD\", \n",
        "    \"USD_CAD\", \n",
        "    \"NZD_USD\"\n",
        "]\n",
        "\n",
        "# Number of candles ~5 year of 1-hour data\n",
        "NUM_CANDLES = 43800\n",
        "TIMEFRAME = \"H1\"\n",
        "\n",
        "# Ensure raw data directory exists\n",
        "import os\n",
        "os.makedirs(\"data/raw\", exist_ok=True)\n",
        "\n",
        "print(f\"Collecting {NUM_CANDLES} candles per pair ({TIMEFRAME})\")\n",
        "print(\"Pairs:\", PAIRS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Data Fetch for One Pair\n",
        "\n",
        "Before fetching data for all 10 pairs,  \n",
        "we will **test the `fetch_live_data()` function** for a single pair (EUR/USD):\n",
        "\n",
        "- Fetch **1 year (~8,760) of 1-hour candles**  \n",
        "- Preview the first few rows to confirm:\n",
        "  - Columns: `timestamp, open, high, low, close, volume`  \n",
        "  - Correct number of rows fetched\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-07-19 08:00:00+00:00</td>\n",
              "      <td>1.16080</td>\n",
              "      <td>1.16186</td>\n",
              "      <td>1.16041</td>\n",
              "      <td>1.16128</td>\n",
              "      <td>6352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-07-19 09:00:00+00:00</td>\n",
              "      <td>1.16133</td>\n",
              "      <td>1.16160</td>\n",
              "      <td>1.15951</td>\n",
              "      <td>1.16062</td>\n",
              "      <td>4379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-07-19 10:00:00+00:00</td>\n",
              "      <td>1.16060</td>\n",
              "      <td>1.16142</td>\n",
              "      <td>1.15954</td>\n",
              "      <td>1.15956</td>\n",
              "      <td>3570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-07-19 11:00:00+00:00</td>\n",
              "      <td>1.15960</td>\n",
              "      <td>1.16006</td>\n",
              "      <td>1.15858</td>\n",
              "      <td>1.16004</td>\n",
              "      <td>4001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-07-19 12:00:00+00:00</td>\n",
              "      <td>1.16006</td>\n",
              "      <td>1.16010</td>\n",
              "      <td>1.15748</td>\n",
              "      <td>1.15864</td>\n",
              "      <td>4080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  timestamp     open     high      low    close  volume\n",
              "0 2018-07-19 08:00:00+00:00  1.16080  1.16186  1.16041  1.16128    6352\n",
              "1 2018-07-19 09:00:00+00:00  1.16133  1.16160  1.15951  1.16062    4379\n",
              "2 2018-07-19 10:00:00+00:00  1.16060  1.16142  1.15954  1.15956    3570\n",
              "3 2018-07-19 11:00:00+00:00  1.15960  1.16006  1.15858  1.16004    4001\n",
              "4 2018-07-19 12:00:00+00:00  1.16006  1.16010  1.15748  1.15864    4080"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.fetch_data import fetch_live_data\n",
        "\n",
        "# Fetch sample data\n",
        "sample_df = fetch_live_data(\"EUR_USD\", candles=NUM_CANDLES, timeframe=TIMEFRAME)\n",
        "\n",
        "# Display first 5 rows\n",
        "sample_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch 1H Historical OHLC Data from OANDA\n",
        "\n",
        "**Objective:**  \n",
        "Fetch 1-hour historical OHLC data for our selected currency pairs from OANDA.  \n",
        "We will fetch **multiple years of data** by paginating requests because OANDA  \n",
        "limits the number of candles per API call (max 5000).\n",
        "\n",
        "**Key Points:**\n",
        "- We use the `instruments.InstrumentsCandles` endpoint.\n",
        "- Data is fetched in batches (pagination) until we reach our desired start date.\n",
        "- Data is saved as CSV in `data/raw/` for each currency pair.\n",
        "- Later, we will **resample** 1H data into 4H, Daily, and Weekly for multi-timeframe analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching data for EUR_USD ...\n",
            "Saved 43800 rows to data/raw/EUR_USD_1H.csv\n",
            "\n",
            "Fetching data for USD_JPY ...\n",
            "Saved 43800 rows to data/raw/USD_JPY_1H.csv\n",
            "\n",
            "Fetching data for GBP_USD ...\n",
            "Saved 43800 rows to data/raw/GBP_USD_1H.csv\n",
            "\n",
            "Fetching data for USD_CHF ...\n",
            "Saved 43800 rows to data/raw/USD_CHF_1H.csv\n",
            "\n",
            "Fetching data for AUD_USD ...\n",
            "Saved 43800 rows to data/raw/AUD_USD_1H.csv\n",
            "\n",
            "Fetching data for USD_CAD ...\n",
            "Saved 43800 rows to data/raw/USD_CAD_1H.csv\n",
            "\n",
            "Fetching data for NZD_USD ...\n",
            "Saved 43800 rows to data/raw/NZD_USD_1H.csv\n",
            "\n",
            "\n",
            "--- Bulk Fetch Completed ---\n",
            "All pairs fetched successfully!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "failed_pairs = []\n",
        "\n",
        "for pair in PAIRS:\n",
        "    print(f\"Fetching data for {pair} ...\")\n",
        "    \n",
        "    try:\n",
        "        df = fetch_live_data(pair, candles=NUM_CANDLES, timeframe=TIMEFRAME)\n",
        "        \n",
        "        if not df.empty:\n",
        "            save_path = f\"data/raw/{pair}_1H.csv\"\n",
        "            df.to_csv(save_path, index=False)\n",
        "            print(f\"Saved {len(df)} rows to {save_path}\\n\")\n",
        "        else:\n",
        "            print(f\"No data fetched for {pair}\\n\")\n",
        "            failed_pairs.append(pair)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {pair}: {e}\\n\")\n",
        "        failed_pairs.append(pair)\n",
        "    \n",
        "    # Pause to avoid hitting API rate limits\n",
        "    time.sleep(3)\n",
        "\n",
        "print(\"\\n--- Bulk Fetch Completed ---\")\n",
        "if failed_pairs:\n",
        "    print(\"⚠ The following pairs failed and need retrying:\", failed_pairs)\n",
        "else:\n",
        "    print(\"All pairs fetched successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Check current git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mdeleted:    data/raw/AUD_USD_forex_data.csv\u001b[m\n",
            "\t\u001b[31mdeleted:    data/raw/EUR_USD_forex_data.csv\u001b[m\n",
            "\t\u001b[31mdeleted:    data/raw/GBP_USD_forex_data.csv\u001b[m\n",
            "\t\u001b[31mdeleted:    data/raw/NZD_USD_forex_data.csv\u001b[m\n",
            "\t\u001b[31mdeleted:    data/raw/USD_CAD_forex_data.csv\u001b[m\n",
            "\t\u001b[31mdeleted:    data/raw/USD_CHF_forex_data.csv\u001b[m\n",
            "\t\u001b[31mdeleted:    data/raw/USD_JPY_forex_data.csv\u001b[m\n",
            "\t\u001b[31mmodified:   jupyter_notebooks/01_data_collection.ipynb\u001b[m\n",
            "\t\u001b[31mmodified:   jupyter_notebooks/02_data_cleaning.ipynb\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdata/raw/AUD_USD_1H.csv\u001b[m\n",
            "\t\u001b[31mdata/raw/EUR_USD_1H.csv\u001b[m\n",
            "\t\u001b[31mdata/raw/GBP_USD_1H.csv\u001b[m\n",
            "\t\u001b[31mdata/raw/NZD_USD_1H.csv\u001b[m\n",
            "\t\u001b[31mdata/raw/USD_CAD_1H.csv\u001b[m\n",
            "\t\u001b[31mdata/raw/USD_CHF_1H.csv\u001b[m\n",
            "\t\u001b[31mdata/raw/USD_JPY_1H.csv\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git status\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Stage all new/updated files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Commit with a descriptive message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git commit -m \"Add raw forex OHLCV data for 7 pairs: Date_collection notebook ran and function coded in fetch_data.py\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
